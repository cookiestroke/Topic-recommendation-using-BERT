{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT search engine",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYYMcLgNa2cy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "outputId": "23208e03-19da-4cee-f94f-9eeebd1730d7"
      },
      "source": [
        "!wget https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n",
        "!unzip uncased_L-12_H-768_A-12.zip\n",
        "!pip install bert-serving-server --no-deps"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-08-24 22:00:58--  https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.20.128, 74.125.142.128, 74.125.195.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.20.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 407727028 (389M) [application/zip]\n",
            "Saving to: ‘uncased_L-12_H-768_A-12.zip’\n",
            "\n",
            "uncased_L-12_H-768_ 100%[===================>] 388.84M   167MB/s    in 2.3s    \n",
            "\n",
            "2020-08-24 22:01:01 (167 MB/s) - ‘uncased_L-12_H-768_A-12.zip’ saved [407727028/407727028]\n",
            "\n",
            "Archive:  uncased_L-12_H-768_A-12.zip\n",
            "   creating: uncased_L-12_H-768_A-12/\n",
            "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.meta  \n",
            "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.data-00000-of-00001  \n",
            "  inflating: uncased_L-12_H-768_A-12/vocab.txt  \n",
            "  inflating: uncased_L-12_H-768_A-12/bert_model.ckpt.index  \n",
            "  inflating: uncased_L-12_H-768_A-12/bert_config.json  \n",
            "Collecting bert-serving-server\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/bd/cab677bbd0c5fb08b72e468371d2bca6ed9507785739b4656b0b5470d90b/bert_serving_server-1.10.0-py3-none-any.whl (61kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 3.8MB/s \n",
            "\u001b[?25hInstalling collected packages: bert-serving-server\n",
            "Successfully installed bert-serving-server-1.10.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvvFoXCR1zeK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 992
        },
        "outputId": "288b07da-3f69-4d6b-d2ba-cc3527c8a5ff"
      },
      "source": [
        "pip install tensorflow==1.15"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.15\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/98/5a99af92fb911d7a88a0005ad55005f35b4c1ba8d75fba02df726cd936e6/tensorflow-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl (412.3MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3MB 40kB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (3.3.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.31.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.15.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.1.2)\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.4MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 56.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (3.12.4)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.12.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.8.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.34.2)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.18.5)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.9.0)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 47.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.2.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15) (2.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.15) (49.2.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.2.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.7.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.1.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=ad9822c770e4112148904b7dc69a168180c1bbdf8e74effce96d9d5e95a1818a\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.11.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: gast, keras-applications, tensorflow-estimator, tensorboard, tensorflow\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorflow-estimator 2.3.0\n",
            "    Uninstalling tensorflow-estimator-2.3.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.3.0\n",
            "  Found existing installation: tensorboard 2.3.0\n",
            "    Uninstalling tensorboard-2.3.0:\n",
            "      Successfully uninstalled tensorboard-2.3.0\n",
            "  Found existing installation: tensorflow 2.3.0\n",
            "    Uninstalling tensorflow-2.3.0:\n",
            "      Successfully uninstalled tensorflow-2.3.0\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLJUBvG72_wo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "outputId": "b90f9cd3-355c-4410-f630-532b4d91eecf"
      },
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "sesh = tf.InteractiveSession()\n",
        "\n",
        "from bert_serving.server.graph import optimize_graph\n",
        "from bert_serving.server.helper import get_args_parser\n",
        "\n",
        "# input dir\n",
        "MODEL_DIR = '/content/uncased_L-12_H-768_A-12' #@param {type:\"string\"}\n",
        "# output dir\n",
        "GRAPH_DIR = '/content/graph/' #@param {type:\"string\"}\n",
        "# output filename\n",
        "GRAPH_OUT = 'extractor.pbtxt' #@param {type:\"string\"}\n",
        "\n",
        "POOL_STRAT = 'REDUCE_MEAN' #@param ['REDUCE_MEAN', 'REDUCE_MAX', \"NONE\"]\n",
        "POOL_LAYER = '-2' #@param {type:\"string\"}\n",
        "SEQ_LEN = '256' #@param {type:\"string\"}\n",
        "\n",
        "tf.gfile.MkDir(GRAPH_DIR)\n",
        "\n",
        "parser = get_args_parser()\n",
        "carg = parser.parse_args(args=['-model_dir', MODEL_DIR,\n",
        "                               '-graph_tmp_dir', GRAPH_DIR,\n",
        "                               '-max_seq_len', str(SEQ_LEN),\n",
        "                               '-pooling_layer', str(POOL_LAYER),\n",
        "                               '-pooling_strategy', POOL_STRAT])\n",
        "\n",
        "tmp_name, config = optimize_graph(carg)\n",
        "graph_fout = os.path.join(GRAPH_DIR, GRAPH_OUT)\n",
        "\n",
        "tf.gfile.Rename(\n",
        "    tmp_name,\n",
        "    graph_fout,\n",
        "    overwrite=True\n",
        ")\n",
        "print(\"\\nSerialized graph to {}\".format(graph_fout))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert_serving/server/helper.py:186: The name tf.logging.set_verbosity is deprecated. Please use tf.compat.v1.logging.set_verbosity instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert_serving/server/helper.py:186: The name tf.logging.ERROR is deprecated. Please use tf.compat.v1.logging.ERROR instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt: 53]:model config: /content/uncased_L-12_H-768_A-12/bert_config.json\n",
            "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt: 56]:checkpoint: /content/uncased_L-12_H-768_A-12/bert_model.ckpt\n",
            "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt: 60]:build graph...\n",
            "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt:132]:load parameters from checkpoint...\n",
            "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt:136]:optimize...\n",
            "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt:144]:freeze...\n",
            "I:\u001b[36mGRAPHOPT\u001b[0m:[gra:opt:149]:write graph to a tmp file: /content/graph/tmplfjd7xih\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Serialized graph to /content/graph/extractor.pbtxt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmgCepvNsJv5"
      },
      "source": [
        "import logging\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.python.estimator.estimator import Estimator\n",
        "from tensorflow.python.estimator.run_config import RunConfig\n",
        "from tensorflow.python.estimator.model_fn import EstimatorSpec\n",
        "from tensorflow.keras.utils import Progbar\n",
        "\n",
        "from bert_serving.server.bert.tokenization import FullTokenizer\n",
        "from bert_serving.server.bert.extract_features import convert_lst_to_features\n",
        "\n",
        "\n",
        "log = logging.getLogger('tensorflow')\n",
        "log.setLevel(logging.INFO)\n",
        "log.handlers = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qIEZPsu-kOzx"
      },
      "source": [
        "GRAPH_PATH = \"/content/graph/extractor.pbtxt\" #@param {type:\"string\"}\n",
        "VOCAB_PATH = \"/content/uncased_L-12_H-768_A-12/vocab.txt\" #@param {type:\"string\"}\n",
        "\n",
        "SEQ_LEN = 256 #@param {type:\"integer\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nULWk9-fkO5I"
      },
      "source": [
        "INPUT_NAMES = ['input_ids', 'input_mask', 'input_type_ids']\n",
        "bert_tokenizer = FullTokenizer(VOCAB_PATH)\n",
        "\n",
        "def build_feed_dict(texts):\n",
        "    \n",
        "    text_features = list(convert_lst_to_features(\n",
        "        texts, SEQ_LEN, SEQ_LEN, \n",
        "        bert_tokenizer, log, False, False))\n",
        "\n",
        "    target_shape = (len(texts), -1)\n",
        "\n",
        "    feed_dict = {}\n",
        "    for iname in INPUT_NAMES:\n",
        "        features_i = np.array([getattr(f, iname) for f in text_features])\n",
        "        features_i = features_i.reshape(target_shape).astype(\"int32\")\n",
        "        feed_dict[iname] = features_i\n",
        "\n",
        "    return feed_dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljud_8WXIMeC"
      },
      "source": [
        "def build_input_fn(container):\n",
        "    \n",
        "    def gen():\n",
        "        while True:\n",
        "          try:\n",
        "            yield build_feed_dict(container.get())\n",
        "          except:\n",
        "            yield build_feed_dict(container.get())\n",
        "\n",
        "    def input_fn():\n",
        "        return tf.data.Dataset.from_generator(\n",
        "            gen,\n",
        "            output_types={iname: tf.int32 for iname in INPUT_NAMES},\n",
        "            output_shapes={iname: (None, None) for iname in INPUT_NAMES})\n",
        "    return input_fn\n",
        "\n",
        "class DataContainer:\n",
        "  def __init__(self):\n",
        "    self._texts = None\n",
        "  \n",
        "  def set(self, texts):\n",
        "    if type(texts) is str:\n",
        "      texts = [texts]\n",
        "    self._texts = texts\n",
        "    \n",
        "  def get(self):\n",
        "    return self._texts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mr4gQqBKS1rp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7617b0dc-e48c-48a4-b1b9-60dd5715fc49"
      },
      "source": [
        "def model_fn(features, mode):\n",
        "    with tf.gfile.GFile(GRAPH_PATH, 'rb') as f:\n",
        "        graph_def = tf.GraphDef()\n",
        "        graph_def.ParseFromString(f.read())\n",
        "        \n",
        "    output = tf.import_graph_def(graph_def,\n",
        "                                 input_map={k + ':0': features[k] for k in INPUT_NAMES},\n",
        "                                 return_elements=['final_encodes:0'])\n",
        "\n",
        "    return EstimatorSpec(mode=mode, predictions={'output': output[0]})\n",
        "  \n",
        "estimator = Estimator(model_fn=model_fn)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using temporary folder as model directory: /tmp/tmpvj33p7yi\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37oYNYf6MX1R"
      },
      "source": [
        "def batch(iterable, n=1):\n",
        "    l = len(iterable)\n",
        "    for ndx in range(0, l, n):\n",
        "        yield iterable[ndx:min(ndx + n, l)]\n",
        "\n",
        "def build_vectorizer(_estimator, _input_fn_builder, batch_size=128):\n",
        "  container = DataContainer()\n",
        "  predict_fn = _estimator.predict(_input_fn_builder(container), yield_single_examples=False)\n",
        "  \n",
        "  def vectorize(text, verbose=False):\n",
        "    x = []\n",
        "    bar = Progbar(len(text))\n",
        "    for text_batch in batch(text, batch_size):\n",
        "      container.set(text_batch)\n",
        "      x.append(next(predict_fn)['output'])\n",
        "      if verbose:\n",
        "        bar.add(len(text_batch))\n",
        "      \n",
        "    r = np.vstack(x)\n",
        "    return r\n",
        "  \n",
        "  return vectorize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqTg_labMb3E"
      },
      "source": [
        "bert_vectorizer = build_vectorizer(estimator, build_input_fn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etpTDXf-MX5H",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        },
        "outputId": "c762aa47-56a8-40d0-c796-4adb32302e16"
      },
      "source": [
        "bert_vectorizer(64*['sample text']).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/array_ops.py:1475: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(64, 768)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoYOSce16iBG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "outputId": "ff784fb1-8238-4324-e6ff-a10dbcc1bc1a"
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import reuters\n",
        "\n",
        "nltk.download(\"reuters\")\n",
        "nltk.download(\"punkt\")\n",
        "\n",
        "max_samples = 256\n",
        "categories = ['wheat', 'tea', 'strategic-metal', \n",
        "              'housing', 'money-supply', 'fuel']\n",
        "\n",
        "S, X, Y = [], [], []\n",
        "\n",
        "for category in categories:\n",
        "  print(category)\n",
        "  \n",
        "  sents = reuters.sents(categories=category)\n",
        "  sents = [' '.join(sent) for sent in sents][:max_samples]\n",
        "  X.append(bert_vectorizer(sents, verbose=True))\n",
        "  Y += [category] * len(sents)\n",
        "  S += sents\n",
        "  \n",
        "X = np.vstack(X) \n",
        "X.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "wheat\n",
            "256/256 [==============================] - 4s 16ms/step\n",
            "tea\n",
            "154/154 [==============================] - 2s 16ms/step\n",
            "strategic-metal\n",
            "200/200 [==============================] - 3s 16ms/step\n",
            "housing\n",
            "139/139 [==============================] - 2s 16ms/step\n",
            "money-supply\n",
            "256/256 [==============================] - 4s 16ms/step\n",
            "fuel\n",
            "129/129 [==============================] - 2s 16ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1134, 768)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17mZWfpV_RBw"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zE9vB5fIuD3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "outputId": "82e64498-b8ca-478c-b6cf-12e704f9062b"
      },
      "source": [
        "Xtr, Xts, Ytr, Yts = train_test_split(X, Y, random_state=34)\n",
        "\n",
        "mlp = LogisticRegression()\n",
        "mlp.fit(Xtr, Ytr)\n",
        "\n",
        "print(classification_report(Yts, mlp.predict(Xts)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                 precision    recall  f1-score   support\n",
            "\n",
            "           fuel       0.75      0.81      0.78        26\n",
            "        housing       0.73      0.75      0.74        32\n",
            "   money-supply       0.84      0.88      0.86        75\n",
            "strategic-metal       0.88      0.90      0.89        48\n",
            "            tea       0.85      0.80      0.82        44\n",
            "          wheat       0.94      0.86      0.90        59\n",
            "\n",
            "       accuracy                           0.85       284\n",
            "      macro avg       0.83      0.83      0.83       284\n",
            "   weighted avg       0.85      0.85      0.85       284\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SA6JCVwa8IhT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "44b91229-0d17-4ddb-bdd3-4985b16288f0"
      },
      "source": [
        "graph = tf.Graph()\n",
        "sess = tf.InteractiveSession(graph=graph)\n",
        "\n",
        "dim = X.shape[1]\n",
        "\n",
        "Q = tf.placeholder(\"float\", [dim])\n",
        "S = tf.placeholder(\"float\", [None, dim])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py:1750: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
            "  warnings.warn('An interactive session is already active. This can '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmLDDjbhIu-1"
      },
      "source": [
        "squared_distance = tf.reduce_sum(tf.pow(Q - S, 2), reduction_indices=1)\n",
        "distance = tf.sqrt(squared_distance)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEHys2u1Uqsc"
      },
      "source": [
        "top_k = 10\n",
        "\n",
        "top_neg_dists, top_indices = tf.math.top_k(tf.negative(distance), k=top_k)\n",
        "top_dists = tf.negative(top_neg_dists)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7doXw3Z-kdB"
      },
      "source": [
        "from sklearn.metrics.pairwise import euclidean_distances"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOPb3SRzFqqT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "7faf6a0a-194e-42f9-eca3-8bc880581aa7"
      },
      "source": [
        "top_indices.eval({Q:X[0], S:X})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0,   37,  273,   69,   33,  241,   75,   26, 1066,   72],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGrb-FahFqwV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "fed1dddd-c474-4a65-c097-3439cdef0e4d"
      },
      "source": [
        "np.argsort(euclidean_distances(X[:1], X)[0])[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0,   37,  273,   69,   33,  241,   75,   26, 1066,   72])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yDVIZoQCGJY"
      },
      "source": [
        "Q = tf.placeholder(\"float\", [dim])\n",
        "S = tf.placeholder(\"float\", [None, dim])\n",
        "\n",
        "Qr = tf.reshape(Q, (1, -1))\n",
        "\n",
        "PP = tf.keras.backend.batch_dot(S, S, axes=1)\n",
        "QQ = tf.matmul(Qr, tf.transpose(Qr))\n",
        "PQ = tf.matmul(S, tf.transpose(Qr))\n",
        "\n",
        "distance = PP - 2 * PQ + QQ\n",
        "distance = tf.sqrt(tf.reshape(distance, (-1,)))\n",
        "\n",
        "top_neg_dists, top_indices = tf.math.top_k(tf.negative(distance), k=top_k)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OEWw7LOLZdCc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "01f212d8-db1b-4361-aa06-684658d01fbb"
      },
      "source": [
        "top_indices.eval({Q:X[0], S:X})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0,   37,  273,   69,   33,  241,   75,   26, 1066,   72],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESN3ZFxw346p"
      },
      "source": [
        "Q = tf.placeholder(\"float\", [dim])\n",
        "S = tf.placeholder(\"float\", [None, dim])\n",
        "S_norm = tf.placeholder(\"float\", [None, 1])\n",
        "\n",
        "Qr = tf.reshape(Q, (1, -1))\n",
        "\n",
        "PP = S_norm\n",
        "QQ = tf.matmul(Qr, tf.transpose(Qr))\n",
        "PQ = tf.matmul(S, tf.transpose(Qr))\n",
        "\n",
        "distance = PP - 2 * PQ + QQ\n",
        "distance = tf.sqrt(tf.reshape(distance, (-1,)))\n",
        "\n",
        "top_neg_dists, top_indices = tf.math.top_k(tf.negative(distance), k=top_k)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXEeJHgB4JNw"
      },
      "source": [
        "X_norm = np.sum(X**2, axis=1).reshape((-1,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MPn1RWt58kXk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "e54da706-58f0-4281-9c76-c1857f44b7c8"
      },
      "source": [
        "top_indices.eval({Q:X[0], S:X, S_norm: X_norm})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0,   37,  273,   69,   33,  241,   75,   26, 1066,   72],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1U4xy5sETxf"
      },
      "source": [
        "class L2Retriever:\n",
        "    def __init__(self, dim, top_k=3, use_norm=False, use_gpu=True):\n",
        "        self.dim = dim\n",
        "        self.top_k = top_k\n",
        "        self.use_norm = use_norm\n",
        "        config = tf.ConfigProto(\n",
        "            device_count={'GPU': (1 if use_gpu else 0)}\n",
        "        )\n",
        "        self.session = tf.Session(config=config)\n",
        "        \n",
        "        self.norm = None\n",
        "        self.query = tf.placeholder(\"float\", [self.dim])\n",
        "        self.kbase = tf.placeholder(\"float\", [None, self.dim])\n",
        "        \n",
        "        self.build_graph()\n",
        "\n",
        "    def build_graph(self):\n",
        "      \n",
        "        if self.use_norm:\n",
        "            self.norm = tf.placeholder(\"float\", [None, 1])\n",
        "\n",
        "        distance = dot_l2_distances(self.kbase, self.query, self.norm)\n",
        "        top_neg_dists, top_indices = tf.math.top_k(tf.negative(distance), k=self.top_k)\n",
        "        top_dists = tf.negative(top_neg_dists)\n",
        "\n",
        "        self.top_distances = top_dists\n",
        "        self.top_indices = top_indices\n",
        "\n",
        "    def predict(self, kbase, query, norm=None):\n",
        "        query = np.squeeze(query)\n",
        "        feed_dict = {self.query: query, self.kbase: kbase}\n",
        "        if self.use_norm:\n",
        "          feed_dict[self.norm] = norm\n",
        "        \n",
        "        I, D = self.session.run([self.top_indices, self.top_distances],\n",
        "                                feed_dict=feed_dict)\n",
        "        \n",
        "        return I, D\n",
        "      \n",
        "def dot_l2_distances(kbase, query, norm=None):\n",
        "    query = tf.reshape(query, (1, -1))\n",
        "    \n",
        "    if norm is None:\n",
        "      XX = tf.keras.backend.batch_dot(kbase, kbase, axes=1)\n",
        "    else:\n",
        "      XX = norm\n",
        "    YY = tf.matmul(query, tf.transpose(query))\n",
        "    XY = tf.matmul(kbase, tf.transpose(query))\n",
        "    \n",
        "    distance = XX - 2 * XY + YY\n",
        "    distance = tf.sqrt(tf.reshape(distance, (-1,)))\n",
        "    \n",
        "    return distance"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AEdGP6OGUM7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "986883b7-c1df-4303-e92b-a0c86780b4e6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWJIrTVXZdQF"
      },
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "df=pd.read_csv('/content/drive/My Drive/stacko.csv')\n",
        "plot = {}\n",
        "metadata = {}\n",
        "topic_data = {}\n",
        "\n",
        "df = df.dropna()\n",
        "# df.isnull().sum()\n",
        "\n",
        "for id, text in df[['id','text']].values:\n",
        "  plot[id] = text \n",
        "\n",
        "for id, Topics, Tags in df[['id','Topics','Tags']].values:\n",
        "  label = Tags.split()\n",
        "  if len(label):\n",
        "    metadata[id] = {\"name\": Topics,\n",
        "                          \"label\": label}\n",
        "\n",
        "for id in set(plot.keys())&set(metadata.keys()):\n",
        "  topic_data[metadata[id]['name']] = {\"label\": metadata[id]['label'],\n",
        "                                            \"plot\": plot[id]}\n",
        "\n",
        "X, Y, names = [], [], []\n",
        "\n",
        "for topic_name, topic_meta in topic_data.items():\n",
        "  X.append(topic_meta['plot'])\n",
        "  Y.append(topic_meta['label'])\n",
        "  names.append(topic_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLbIxcQxWcSB"
      },
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "df=pd.read_csv('/content/drive/My Drive/stacko.csv')\n",
        "text = {}\n",
        "metadata = {}\n",
        "topic_data = {}\n",
        "\n",
        "df = df.dropna()\n",
        "# df.isnull().sum()\n",
        "\n",
        "for id, text in df[['id','text']].values:\n",
        "  text[id] = text \n",
        "\n",
        "for id, Topics, Tags in df[['id','Topics','Tags']].values:\n",
        "  label = Tags.split()\n",
        "  if len(label):\n",
        "    metadata[id] = {\"name\": Topics,\n",
        "                          \"label\": label}\n",
        "\n",
        "for id in set(plot.keys())&set(metadata.keys()):\n",
        "  topic_data[metadata[id]['name']] = {\"label\": metadata[id]['label'],\n",
        "                                            \"text\": text[id]}\n",
        "\n",
        "X, Y, names = [], [], []\n",
        "\n",
        "for topic_name, topic_meta in topic_data.items():\n",
        "  X.append(topic_meta['text'])\n",
        "  Y.append(topic_meta['label'])\n",
        "  names.append(topic_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7VJ_FjNGF7O"
      },
      "source": [
        "X_vect=np.load('/content/drive/My Drive/X_vect1.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smgRnX2-Gviw"
      },
      "source": [
        "# X_vect = bert_vectorizer(X, verbose=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4_pN0PICAPu"
      },
      "source": [
        "X_square_norm = np.sum(X_vect**2, axis=1).reshape((-1,1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F4Gd4TZEVOJ9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8d3e1d60-0b84-436b-9123-cab32ea3e9c3"
      },
      "source": [
        "test_id = 10060 # The Matrix\n",
        "\n",
        "retriever = L2Retriever(768, use_norm=True, top_k=10, use_gpu=False)\n",
        "%timeit retriever.predict(X_vect, X_vect[test_id], X_square_norm)[0][1:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10 loops, best of 3: 123 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N9AuVbwT-LKb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "194559aa-11e7-4eda-9476-f39dc77cafe2"
      },
      "source": [
        "retriever = L2Retriever(768, use_norm=False, top_k=10, use_gpu=True)\n",
        "%timeit retriever.predict(X_vect, X_vect[test_id])[0][1:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 loop, best of 3: 328 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LCJOkYZB-LNq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a59e5834-d9c3-4ead-8c84-9c59617f4a9d"
      },
      "source": [
        "%timeit euclidean_distances(X_vect, X_vect[test_id:test_id+1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 loop, best of 3: 1.5 s per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHXTVw15N8x1"
      },
      "source": [
        "def buildRecommender(topic_names, vectorized_plots, top_k=10):\n",
        "  retriever = L2Retriever(vectorized_plots.shape[1], use_norm=True, top_k=top_k, use_gpu=False)\n",
        "  vectorized_norm = np.sum(vectorized_plots**2, axis=1).reshape((-1,1))\n",
        "  \n",
        "  def recommend(query):\n",
        "    try:\n",
        "      idx = retriever.predict(vectorized_plots, \n",
        "                              vectorized_plots[topic_names.index(query)], \n",
        "                              vectorized_norm)[0][1:]\n",
        "      for i in idx:\n",
        "        print(names[i])\n",
        "    except ValueError:\n",
        "      print(\"{} not found in topic db. Suggestions:\")\n",
        "      # m=8\n",
        "      # n=0\n",
        "      dic={}\n",
        "      q=[k for k in query.lower().split() if k not in ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]]\n",
        "      for i, name in enumerate(topic_names):\n",
        "        l=0\n",
        "        for j in q:\n",
        "          if j in name.lower():\n",
        "            l+=1\n",
        "        dic[i]=l\n",
        "      # for i in sorted(dic.items(), key=lambda x: x[1], reverse=True)[:10]:\n",
        "      #   print(i[0], names[i[0]])\n",
        "      q=sorted(dic.items(), key=lambda x: x[1], reverse=True)[0]\n",
        "      print(names[q[0]])\n",
        "      recommend(names[q[0]])\n",
        "          \n",
        "  return recommend"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1knPUoX-LTb"
      },
      "source": [
        "recommend = buildRecommender(names, X_vect)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbT-2kOlG-y3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "outputId": "4e315f2e-ea5d-4338-e939-513442f40ed2"
      },
      "source": [
        "recommend(\"how to download a file on Chrome without auto renaming file to “download”?\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "How to download a file on clicking the name of file using PHP?\n",
            "How to create a ZIP file using PHP and delete it after user downloads it?\n",
            "How to force a file to download in PHP\n",
            "How to change the file name of an uploaded file in Django?\n",
            "How to start file download instantly using php headers\n",
            "How to get full filepath when uploading files in PHP?\n",
            "How to start automatic download of a file in Internet Explorer?\n",
            "Q: How to delete file using file observer in Android?\n",
            "Chrome extension: How to save a file on disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gP-L15jVLU2i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "1fdb4769-b620-4336-d0a6-b864a1da3b35"
      },
      "source": [
        "recommend(\"download a python code in selenium\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{} not found in topic db. Suggestions:\n",
            "Python: Unable to download with selenium in webpage\n",
            "Use default Chrome profile with Selenium in Python\n",
            "Q: Selenium click does not trigger event on website (python)\n",
            "Chrome headless file download with Selenium in Python\n",
            "Folium map not displaying in Django webpage\n",
            "Q: How can I “click” download button on selenium in python\n",
            "Q: Copy text from website using Selenium for python\n",
            "[python][selenium] on-screen position of element\n",
            "Radio button does not get clicked in Selenium / Python\n",
            "Scraping infinite scrolling website with Selenium in Python\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dC9QUKWTL2ki",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "4208cd03-1ce9-4376-b5ae-79868d6a5be7"
      },
      "source": [
        "df['Topics'].sample() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "392974    How do I filter all HTML tags except a certain...\n",
              "Name: Topics, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbyKQZF2dMBC"
      },
      "source": [
        "# np.save('/content/drive/My Drive/X_vect1',X_vect)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQnN5_ZeOOpu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "b3d4320a-3a69-4f32-f726-e06e5b5132e9"
      },
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "df=pd.read_csv('/content/drive/My Drive/stacko1.csv')\n",
        "\n",
        "max_samples = 256\n",
        "categories=set()\n",
        "for i in df['Category']:\n",
        "  categories.add(i)\n",
        "categories\n",
        "A, B, C = [], [], []\n",
        "\n",
        "for category in categories:\n",
        "  print(category)\n",
        "  # sents = reuters.sents(categories=category)\n",
        "  # sents = [' '.join(sent) for sent in sents][:max_samples]\n",
        "  sents = [' '.join(row['text']) for index,row in df.iterrows() if row['Category']==category][:max_samples]\n",
        "  # A.append(bert_vectorizer(sents, verbose=True))\n",
        "  B += [category] * len(sents)\n",
        "  C += sents\n",
        "  \n",
        "# A = np.vstack(A) \n",
        "# A.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "full stack\n",
            "artificial intelligence\n",
            "json\n",
            "git\n",
            "data science\n",
            "machine learning\n",
            "php\n",
            "python\n",
            "sql\n",
            "data analytics\n",
            "css\n",
            "html\n",
            "react js\n",
            "javascript\n",
            "bioinformatics\n",
            "big data\n",
            "asana\n",
            "neural networks\n",
            "mysql\n",
            "statistics\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIqW2YvwguiJ"
      },
      "source": [
        "A=np.load('/content/drive/My Drive/A-san.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q73YUxZNgikU"
      },
      "source": [
        "# np.save('/content/drive/My Drive/A-san',A)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEBSKxh3sbBZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "64d7d5b0-2030-48b5-df08-8bda7dbceb6e"
      },
      "source": [
        "Xtr, Xts, Ytr, Yts = train_test_split(A, B, random_state=34)\n",
        "\n",
        "mlp = LogisticRegression(max_iter=5000)\n",
        "mlp.fit(Xtr, Ytr)\n",
        "\n",
        "print(classification_report(Yts, mlp.predict(Xts)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                         precision    recall  f1-score   support\n",
            "\n",
            "artificial intelligence       0.90      0.95      0.92        58\n",
            "                  asana       0.52      0.59      0.55        56\n",
            "               big data       0.71      0.66      0.68        67\n",
            "         bioinformatics       0.97      0.91      0.94        68\n",
            "                    css       0.36      0.41      0.38        59\n",
            "         data analytics       0.84      0.92      0.88        71\n",
            "           data science       0.46      0.31      0.37        67\n",
            "             full stack       0.47      0.51      0.49        61\n",
            "                    git       0.75      0.82      0.78        62\n",
            "                   html       0.49      0.56      0.52        57\n",
            "             javascript       0.96      0.96      0.96        73\n",
            "                   json       0.58      0.46      0.51        76\n",
            "       machine learning       0.75      0.72      0.74        68\n",
            "                  mysql       0.93      1.00      0.96        64\n",
            "        neural networks       0.22      0.24      0.23        63\n",
            "                    php       0.87      0.79      0.83        70\n",
            "                 python       0.68      0.72      0.70        54\n",
            "               react js       0.91      0.95      0.93        56\n",
            "                    sql       0.67      0.67      0.67        61\n",
            "             statistics       0.85      0.80      0.82        69\n",
            "\n",
            "               accuracy                           0.70      1280\n",
            "              macro avg       0.69      0.70      0.69      1280\n",
            "           weighted avg       0.70      0.70      0.70      1280\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uATPuCW-lwrA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "b4a78b18-bfe2-4a05-8c4c-41173fd0b657"
      },
      "source": [
        "Xtr, Xts, Ytr, Yts = train_test_split(A, B, random_state=34)\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "mlp = RandomForestClassifier(n_estimators=100)\n",
        "mlp.fit(Xtr, Ytr)\n",
        "\n",
        "print(classification_report(Yts, mlp.predict(Xts)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                         precision    recall  f1-score   support\n",
            "\n",
            "artificial intelligence       0.66      0.84      0.74        58\n",
            "                  asana       0.39      0.43      0.41        56\n",
            "               big data       0.43      0.39      0.41        67\n",
            "         bioinformatics       0.65      0.81      0.72        68\n",
            "                    css       0.12      0.12      0.12        59\n",
            "         data analytics       0.67      0.79      0.72        71\n",
            "           data science       0.19      0.09      0.12        67\n",
            "             full stack       0.33      0.25      0.28        61\n",
            "                    git       0.49      0.63      0.55        62\n",
            "                   html       0.25      0.30      0.27        57\n",
            "             javascript       0.84      0.84      0.84        73\n",
            "                   json       0.39      0.22      0.28        76\n",
            "       machine learning       0.51      0.51      0.51        68\n",
            "                  mysql       0.74      0.95      0.84        64\n",
            "        neural networks       0.08      0.05      0.06        63\n",
            "                    php       0.71      0.77      0.74        70\n",
            "                 python       0.54      0.57      0.56        54\n",
            "               react js       0.64      0.80      0.71        56\n",
            "                    sql       0.42      0.41      0.41        61\n",
            "             statistics       0.71      0.65      0.68        69\n",
            "\n",
            "               accuracy                           0.52      1280\n",
            "              macro avg       0.49      0.52      0.50      1280\n",
            "           weighted avg       0.49      0.52      0.50      1280\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C453xc3YnoCU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "12f19ff1-2cfe-4129-c393-564f35d29c32"
      },
      "source": [
        "Xtr, Xts, Ytr, Yts = train_test_split(A, B, random_state=34)\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "knn_classifier = KNeighborsClassifier()\n",
        "knn_classifier.fit(Xtr, Ytr)\n",
        "\n",
        "print(classification_report(Yts, knn_classifier.predict(Xts)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                         precision    recall  f1-score   support\n",
            "\n",
            "artificial intelligence       0.37      0.90      0.53        58\n",
            "                  asana       0.22      0.52      0.31        56\n",
            "               big data       0.22      0.25      0.24        67\n",
            "         bioinformatics       0.62      0.85      0.72        68\n",
            "                    css       0.25      0.25      0.25        59\n",
            "         data analytics       0.50      0.83      0.62        71\n",
            "           data science       0.26      0.16      0.20        67\n",
            "             full stack       0.38      0.25      0.30        61\n",
            "                    git       0.48      0.44      0.46        62\n",
            "                   html       0.28      0.19      0.23        57\n",
            "             javascript       0.95      0.74      0.83        73\n",
            "                   json       0.50      0.18      0.27        76\n",
            "       machine learning       0.44      0.35      0.39        68\n",
            "                  mysql       0.71      0.94      0.81        64\n",
            "        neural networks       0.06      0.02      0.03        63\n",
            "                    php       0.82      0.76      0.79        70\n",
            "                 python       0.61      0.35      0.45        54\n",
            "               react js       0.65      0.61      0.63        56\n",
            "                    sql       0.42      0.26      0.32        61\n",
            "             statistics       0.66      0.54      0.59        69\n",
            "\n",
            "               accuracy                           0.47      1280\n",
            "              macro avg       0.47      0.47      0.45      1280\n",
            "           weighted avg       0.48      0.47      0.45      1280\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RImK14X2oYU4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "c7f30fd2-5ebc-4370-e992-047e674805aa"
      },
      "source": [
        "Xtr, Xts, Ytr, Yts = train_test_split(A, B, random_state=34)\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "snn_classifier = MLPClassifier(max_iter=1000)\n",
        "snn_classifier.fit(Xtr, Ytr)\n",
        "\n",
        "print(classification_report(Yts, snn_classifier.predict(Xts)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                         precision    recall  f1-score   support\n",
            "\n",
            "artificial intelligence       0.91      0.90      0.90        58\n",
            "                  asana       0.46      0.50      0.48        56\n",
            "               big data       0.76      0.58      0.66        67\n",
            "         bioinformatics       1.00      0.90      0.95        68\n",
            "                    css       0.36      0.34      0.35        59\n",
            "         data analytics       0.88      0.92      0.90        71\n",
            "           data science       0.38      0.40      0.39        67\n",
            "             full stack       0.57      0.52      0.55        61\n",
            "                    git       0.62      0.84      0.71        62\n",
            "                   html       0.42      0.49      0.45        57\n",
            "             javascript       0.78      0.97      0.87        73\n",
            "                   json       0.51      0.41      0.45        76\n",
            "       machine learning       0.79      0.71      0.74        68\n",
            "                  mysql       0.90      0.98      0.94        64\n",
            "        neural networks       0.16      0.19      0.17        63\n",
            "                    php       0.78      0.81      0.80        70\n",
            "                 python       0.75      0.61      0.67        54\n",
            "               react js       0.96      0.91      0.94        56\n",
            "                    sql       0.80      0.64      0.71        61\n",
            "             statistics       0.85      0.80      0.82        69\n",
            "\n",
            "               accuracy                           0.68      1280\n",
            "              macro avg       0.68      0.67      0.67      1280\n",
            "           weighted avg       0.68      0.68      0.68      1280\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqB_6tsvqBJQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "outputId": "125e46c6-7cda-4b12-e03b-607a4365b1e4"
      },
      "source": [
        "Xtr, Xts, Ytr, Yts = train_test_split(A, B, random_state=34)\n",
        "from sklearn.svm import SVC\n",
        "svm_classifier = SVC(decision_function_shape='ovr')\n",
        "svm_classifier.fit(Xtr, Ytr)\n",
        "\n",
        "print(classification_report(Yts, svm_classifier.predict(Xts)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                         precision    recall  f1-score   support\n",
            "\n",
            "artificial intelligence       0.73      0.84      0.78        58\n",
            "                  asana       0.49      0.52      0.50        56\n",
            "               big data       0.41      0.42      0.41        67\n",
            "         bioinformatics       0.77      0.84      0.80        68\n",
            "                    css       0.20      0.32      0.24        59\n",
            "         data analytics       0.64      0.79      0.71        71\n",
            "           data science       0.27      0.06      0.10        67\n",
            "             full stack       0.26      0.26      0.26        61\n",
            "                    git       0.47      0.61      0.54        62\n",
            "                   html       0.35      0.40      0.37        57\n",
            "             javascript       0.94      0.84      0.88        73\n",
            "                   json       0.41      0.21      0.28        76\n",
            "       machine learning       0.34      0.59      0.43        68\n",
            "                  mysql       0.89      0.91      0.90        64\n",
            "        neural networks       0.29      0.06      0.10        63\n",
            "                    php       0.75      0.74      0.75        70\n",
            "                 python       0.65      0.52      0.58        54\n",
            "               react js       0.65      0.77      0.70        56\n",
            "                    sql       0.36      0.43      0.39        61\n",
            "             statistics       0.76      0.59      0.67        69\n",
            "\n",
            "               accuracy                           0.54      1280\n",
            "              macro avg       0.53      0.54      0.52      1280\n",
            "           weighted avg       0.54      0.54      0.52      1280\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rw0A-DLlmYez"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}